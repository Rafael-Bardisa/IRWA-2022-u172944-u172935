{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "iiB2f3Y-5eXS",
   "metadata": {
    "id": "iiB2f3Y-5eXS"
   },
   "source": [
    "# Information Retrieval and Web Analytics\n",
    "\n",
    "# Part 1: Text Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf6d8963-aa98-40f2-8399-94b866d9c18e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf6d8963-aa98-40f2-8399-94b866d9c18e",
    "outputId": "fb8e70ea-c01f-40d0-db5e-1fabdfd92041"
   },
   "outputs": [],
   "source": [
    "# mount google drive if using google collab, else skip\n",
    "# we are not using it because it is more comfortable to use jupyter lab\n",
    "\n",
    "BASEDIR = '.'\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASEDIR = 'drive/MyDrive'\n",
    "    \n",
    "except ModuleNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e2a1daf4-842d-4c00-b294-0efef0747570",
   "metadata": {
    "id": "e2a1daf4-842d-4c00-b294-0efef0747570"
   },
   "outputs": [],
   "source": [
    "# required imports for the notebook\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "HeK-m09ohD79",
   "metadata": {
    "id": "HeK-m09ohD79"
   },
   "outputs": [],
   "source": [
    "# read the json file as a dataframe\n",
    "df = pd.read_json(f'{BASEDIR}/data/tw_hurricane_data.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b_miHSTziZ78",
   "metadata": {
    "id": "b_miHSTziZ78"
   },
   "outputs": [],
   "source": [
    "# create a dataframe with the features wanted\n",
    "tweets = df[['id','full_text', 'user','created_at','entities', 'favorite_count', 'retweet_count']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "W5rX-Zv-vOVN",
   "metadata": {
    "id": "W5rX-Zv-vOVN"
   },
   "outputs": [],
   "source": [
    "# correct different features inside the dataframe\n",
    "# create lists for the features we want to modify\n",
    "url=[]\n",
    "hashtags=[]\n",
    "user=[]\n",
    "# iterate through the whole dataset\n",
    "for ele in range(len(tweets)):\n",
    "  hashtags.append([hashtag['text'] for hashtag in tweets['entities'][ele]['hashtags']])  # extract the hashtags\n",
    "  user.append(tweets['user'][ele]['name'])                    # extract user names\n",
    "  try:\n",
    "    url.append(tweets['entities'][ele]['media'][0][\"expanded_url\"]) # extract url if this exists\n",
    "  except: \n",
    "    url.append('')\n",
    "# assign this lists to columns to dataframe\n",
    "tweets['url'] = url\n",
    "tweets['hashtags'] = has\n",
    "tweets['user'] = user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "LPkyUQNJx-aB",
   "metadata": {
    "id": "LPkyUQNJx-aB"
   },
   "outputs": [],
   "source": [
    "# drop the column used before that would not be needed after\n",
    "tweets.drop(['entities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "RQLRhINXeYGV",
   "metadata": {
    "id": "RQLRhINXeYGV"
   },
   "outputs": [],
   "source": [
    "# reuse of the function shown in class to transform text into lowercase and erase stop words...\n",
    "def build_terms(line):\n",
    "    \"\"\"\n",
    "    Preprocess the article text (title + body) removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "    \n",
    "    Argument:\n",
    "    line -- string (text) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    line - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    line = line.lower()\n",
    "    line = line.split()  # Tokenize the text to get a list of terms\n",
    "    line = [x for x in line if x not in stop_words]  # eliminate the stopwords\n",
    "    line = [stemmer.stem(word) for word in line] # perform stemming (HINT: use List Comprehension)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "hceA51tF5SK9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hceA51tF5SK9",
    "outputId": "ad192eb7-f05c-456d-bd7e-0edf8ec6826d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/r5h7_tb55pvdx8zbc30wjdm80000gp/T/ipykernel_28874/2274894086.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets['full_text'][ele] = ' '.join(text)\n",
      "/var/folders/98/r5h7_tb55pvdx8zbc30wjdm80000gp/T/ipykernel_28874/2274894086.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets['user'][ele] = tweets['user'][ele].lower()\n",
      "/var/folders/98/r5h7_tb55pvdx8zbc30wjdm80000gp/T/ipykernel_28874/2274894086.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets['hashtags'][ele] = map(str.lower, tweets['hashtags'][ele])\n"
     ]
    }
   ],
   "source": [
    "# use the function above to correct the tweet and also convert into lowercase the hastags and usernames\n",
    "for ele in range(len(tweets)):\n",
    "    text = build_terms(tweets['full_text'][ele])\n",
    "    text = [word for word in text if word.startswith('#')==False]\n",
    "    text = [word for word in text if word.startswith('@')==False]\n",
    "    text = [word for word in text if word.startswith('http')==False]\n",
    "    tweets['full_text'][ele] = ' '.join(text)\n",
    "    tweets['user'][ele] = tweets['user'][ele].lower()\n",
    "    # hashtags may be more than one, so apply lowercase function to all its elements\n",
    "    tweets['hashtags'][ele] = map(str.lower, tweets['hashtags'][ele])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "28lVkxbeLE5g",
   "metadata": {
    "id": "28lVkxbeLE5g"
   },
   "outputs": [],
   "source": [
    "# get dictionary to map tweet ids to doc ids\n",
    "# we know the ids file is a list of [doc_id \\t tweet_id]\n",
    "with open(f'{BASEDIR}/data/tweet_document_ids_map.csv', 'r') as id_file:\n",
    "    ids = csv.reader(id_file, delimiter=\"\\t\")\n",
    "    dict_ids = {id_to_id[1]: id_to_id[0] for id_to_id in list(ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "GMZdPWXcLjN4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMZdPWXcLjN4",
    "outputId": "e0be8f77-c191-49fe-95ec-1a1a2cfc479a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/r5h7_tb55pvdx8zbc30wjdm80000gp/T/ipykernel_28874/3321124730.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets[\"id\"][ele] = dict_ids[tweet_id]\n"
     ]
    }
   ],
   "source": [
    "# map tweet ids with doc ids\n",
    "for ele in range(len(tweets)):\n",
    "    tweet_id = str(tweets[\"id\"][ele])\n",
    "    tweets[\"id\"][ele] = dict_ids[tweet_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3Pjhk-3EUITY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "3Pjhk-3EUITY",
    "outputId": "df258f22-3efc-40de-9784-bd6ed0742a6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>user</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>url</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_1</td>\n",
       "      <td>keep spin us 7 pmâ€¦go away already.</td>\n",
       "      <td>suzðŸ‘»</td>\n",
       "      <td>2022-09-30 18:39:08+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/suzjdean/status/1575918182...</td>\n",
       "      <td>&lt;map object at 0x12fddb310&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_2</td>\n",
       "      <td>heart go affect wish everyon road current brav...</td>\n",
       "      <td>lytx</td>\n",
       "      <td>2022-09-30 18:39:01+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>&lt;map object at 0x12fdd9180&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc_3</td>\n",
       "      <td>kissimme neighborhood michigan ave.</td>\n",
       "      <td>christopher heath</td>\n",
       "      <td>2022-09-30 18:38:58+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://twitter.com/CHeathWFTV/status/15759181...</td>\n",
       "      <td>&lt;map object at 0x12fdda6e0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc_4</td>\n",
       "      <td>one tree backyard scare poltergeist tree itâ€™ s...</td>\n",
       "      <td>alex âœ¨</td>\n",
       "      <td>2022-09-30 18:38:57+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>&lt;map object at 0x12fdd9630&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc_5</td>\n",
       "      <td>pray everyon affect associ winknews. sympathi ...</td>\n",
       "      <td>tess ðŸ’‹</td>\n",
       "      <td>2022-09-30 18:38:53+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>&lt;map object at 0x12fddbe20&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                          full_text  \\\n",
       "0  doc_1                 keep spin us 7 pmâ€¦go away already.   \n",
       "1  doc_2  heart go affect wish everyon road current brav...   \n",
       "2  doc_3                kissimme neighborhood michigan ave.   \n",
       "3  doc_4  one tree backyard scare poltergeist tree itâ€™ s...   \n",
       "4  doc_5  pray everyon affect associ winknews. sympathi ...   \n",
       "\n",
       "                user                created_at  favorite_count  retweet_count  \\\n",
       "0               suzðŸ‘» 2022-09-30 18:39:08+00:00               0              0   \n",
       "1               lytx 2022-09-30 18:39:01+00:00               0              0   \n",
       "2  christopher heath 2022-09-30 18:38:58+00:00               0              0   \n",
       "3             alex âœ¨ 2022-09-30 18:38:57+00:00               0              0   \n",
       "4             tess ðŸ’‹ 2022-09-30 18:38:53+00:00               0              0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://twitter.com/suzjdean/status/1575918182...   \n",
       "1                                                      \n",
       "2  https://twitter.com/CHeathWFTV/status/15759181...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                      hashtags  \n",
       "0  <map object at 0x12fddb310>  \n",
       "1  <map object at 0x12fdd9180>  \n",
       "2  <map object at 0x12fdda6e0>  \n",
       "3  <map object at 0x12fdd9630>  \n",
       "4  <map object at 0x12fddbe20>  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the head of the dataframe to visualize our result\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4bdc3a76-824d-4f5a-af97-41cc35ea1b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save result in a new csv file\n",
    "tweets.to_csv(f'{BASEDIR}/data/processed_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feefe36-9402-499b-985d-c6f25602f39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
