{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "iiB2f3Y-5eXS",
   "metadata": {
    "id": "iiB2f3Y-5eXS"
   },
   "source": [
    "# Information Retrieval and Web Analytics\n",
    "\n",
    "# Part 2: Indexing and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf6d8963-aa98-40f2-8399-94b866d9c18e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf6d8963-aa98-40f2-8399-94b866d9c18e",
    "outputId": "5b1a8518-e030-44b8-96ec-b65aea7cb8f0"
   },
   "outputs": [],
   "source": [
    "# mount google drive if using google collab, else skip\n",
    "# we are not using it because it is more comfortable to use jupyter lab\n",
    "\n",
    "BASEDIR = '.'\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASEDIR = 'drive/MyDrive'\n",
    "    \n",
    "except ModuleNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2a1daf4-842d-4c00-b294-0efef0747570",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2a1daf4-842d-4c00-b294-0efef0747570",
    "outputId": "36734bed-835a-4bd5-ca43-98fa7530a5cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rafaelbardisarodes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# required imports for the notebook\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from array import array\n",
    "from collections import defaultdict, Counter\n",
    "import functools\n",
    "\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c63017f6-7ced-4d7d-b4b9-875355f082ef",
   "metadata": {
    "id": "c63017f6-7ced-4d7d-b4b9-875355f082ef"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "WHITE = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def benchmark(func):\n",
    "    \"\"\"\n",
    "    Decorador que te mide el tiempo que tarda la funcion en ejecutarse.\n",
    "    Se puede usar como cualquier funcion, e.g. benchmark(func),\n",
    "    pero al ser un decorador la gracia que tiene es que al hacer\n",
    "    @benchmark\n",
    "    def func():...\n",
    "    cada vez que uses func() estaras usando benchmark(func)()\n",
    "    :param func: la funcion que quieres testear\n",
    "    :return: la funcion original envuelta por el codigo de testeo\n",
    "    \"\"\"\n",
    "    def inner(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        print(f'Time taken for {RED}{func.__name__}{WHITE}: {end - start:.4f}')\n",
    "        return result\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "Iq8CBGFPEqTa",
   "metadata": {
    "id": "Iq8CBGFPEqTa"
   },
   "outputs": [],
   "source": [
    "# open results from last practice\n",
    "tweets = pd.read_csv(f'{BASEDIR}/data/processed_tweets.csv')\n",
    "tweets = tweets.reset_index()  # make sure indexes pair with number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yPqSycI3REu6",
   "metadata": {
    "id": "yPqSycI3REu6"
   },
   "source": [
    "### Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99eKgkLSGjsB",
   "metadata": {
    "id": "99eKgkLSGjsB"
   },
   "outputs": [],
   "source": [
    "# reuse of the function shown in class to transform text into lowercase and erase stop words in queries\n",
    "def build_terms(line):\n",
    "    \"\"\"\n",
    "    Preprocess the line removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "    \n",
    "    Argument:\n",
    "    line -- string (text) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    line - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    line = line.lower()\n",
    "    line = line.split()  # Tokenize the text to get a list of terms\n",
    "    line = [x for x in line if x not in stop_words]  # eliminate the stopwords\n",
    "    line = [stemmer.stem(word) for word in line] # perform stemming (HINT: use List Comprehension)\n",
    "    return line\n",
    "\n",
    "\n",
    "@benchmark\n",
    "def create_index(tweets):\n",
    "    \"\"\"\n",
    "    Implement the inverted index\n",
    "    \n",
    "    Argument:\n",
    "    lines -- collection of Wikipedia articles\n",
    "    \n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of documents where these keys appears in (and the positions) as values.\n",
    "    \"\"\"\n",
    "    index = defaultdict(list)\n",
    "    title_index = {}  # dictionary to map page titles to page ids\n",
    "\n",
    "    for tweet in tweets.itertuples(index=True):  # Remember, lines contain all documents from file\n",
    "        tweet_text = tweet.full_text\n",
    "        \n",
    "        # tweet id\n",
    "        tweet_id = int(tweet.id.split(\"_\")[1])\n",
    "\n",
    "        terms = str(tweet_text).split(\" \")  # page_title + page_text\n",
    "\n",
    "        title_index[tweet_id] = tweet.user  ## we do not need to apply get terms to title because it used only to print titles and not in the index\n",
    "        \n",
    "        ## ===============================================================        \n",
    "        ## create the index for the current page and store it in current_page_index (current_page_index)\n",
    "        ## current_page_index ==> { ‘term1’: [current_doc, [list of positions]], ...,‘term_n’: [current_doc, [list of positions]]}\n",
    "\n",
    "        ## Example: if the curr_doc has id 1 and his text is \"web retrieval information retrieval\":\n",
    "\n",
    "        ## current_page_index ==> { ‘web’: [1, [0]], ‘retrieval’: [1, [1,4]], ‘information’: [1, [2]]}\n",
    "\n",
    "        ## the term ‘web’ appears in document 1 in positions 0, \n",
    "        ## the term ‘retrieval’ appears in document 1 in positions 1 and 4\n",
    "        ## ===============================================================\n",
    "\n",
    "        current_page_index = {}\n",
    "\n",
    "        for position, term in enumerate(terms): # terms contains page_title + page_text. Loop over all terms\n",
    "            try:\n",
    "                # if the term is already in the index for the current page (current_page_index)\n",
    "                # append the position to the corresponding list\n",
    "                current_page_index[term][1].append(position)\n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                current_page_index[term] = [tweet_id, array('I', [position])]  #'I' indicates unsigned int (int in Python)\n",
    "\n",
    "        # merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "    return index, title_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "Ib0gaZhiLvhD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ib0gaZhiLvhD",
    "outputId": "4006d949-f1c0-4d2b-9a47-65156ab84f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for \u001b[91mcreate_index\u001b[0m: 0.1629\n"
     ]
    }
   ],
   "source": [
    "index, title_index= create_index(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nHfVOqpgRLnc",
   "metadata": {
    "id": "nHfVOqpgRLnc"
   },
   "source": [
    "### 5 Text queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "F5aBt6wSRO_P",
   "metadata": {
    "id": "F5aBt6wSRO_P"
   },
   "outputs": [],
   "source": [
    "# def query(text)?:\n",
    "# build terms(query)\n",
    "\n",
    "# index = tremendo index\n",
    "# foreach term in query\n",
    "# index = index[term in entry] <- boolean mask, conjunctive AND\n",
    "\n",
    "# return index <- the doc ids\n",
    "# or\n",
    "# return tweets[original_text][index] <- get original text of tweets containing all elements in query\n",
    "\n",
    "def query(text, tweet_index=\"\"):\n",
    "    \"\"\"\n",
    "    search for a given text in the tweet collection using the\n",
    "    inverted index we previously computed\n",
    "    :param text: the query text\n",
    "    :param tweet_index: inverted index of the collection, named as such because context of practice\n",
    "    :return: list of tweet ids containing all (treated) terms in the query\n",
    "    \"\"\"\n",
    "    \n",
    "    # necessary step since same treatment applied to tweets\n",
    "    terms = build_terms(text)\n",
    "    \n",
    "    # select tweet index, defaults to global index but can be specified\n",
    "    tweet_index = tweet_index if tweet_index else index\n",
    "    \n",
    "    plausible_ids = []\n",
    "    for query_term in terms:\n",
    "        # tweet_index[query_term] is list of tweet ids containing query term + position(s) in text, could be useful in the future\n",
    "        # plausible_ids[query_term] = tweet_index[query_term]\n",
    "        \n",
    "        # using sets is convenient for using reduce\n",
    "        plausible_ids.append(set(term_pos[0] for term_pos in tweet_index[query_term]))\n",
    "        \n",
    "    # reduce list of sets to intersection of all\n",
    "    relevant_ids = functools.reduce(lambda a, b: a.intersection(b), plausible_ids)\n",
    "                             \n",
    "    return relevant_ids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f972cec-c2a7-4645-a28a-ab6a7225a533",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1f972cec-c2a7-4645-a28a-ab6a7225a533",
    "outputId": "8dd1566e-209c-48aa-ab83-08edfe81c459"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 484, 762, 2045, 3377, 3996}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(\"keeps us\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bt_s1CwPRPmt",
   "metadata": {
    "id": "Bt_s1CwPRPmt"
   },
   "source": [
    "### Ranking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "M-z_0onURSJX",
   "metadata": {
    "id": "M-z_0onURSJX"
   },
   "outputs": [],
   "source": [
    "# rank(query):\n",
    "# query = build_terms(query)\n",
    "\n",
    "# scores = {}\n",
    "# length = {}\n",
    "# foreach term in query:\n",
    "# w_q = TF-IDF(term, query), docids = query(term)\n",
    "# foreach docid in docids:\n",
    "# scores[docid] += TF-IDF(term, tweets.full_text[docid]) * w_q\n",
    "# ::\n",
    "# foreach docid:\n",
    "# scores[d] /= len(tweets.full_text[docid])\n",
    "\n",
    "# sort scores, return top K\n",
    "\n",
    "\n",
    "# relevant documents = query(query)\n",
    "# foreach document in relevant_documents\n",
    "# TF-IDF(document, query)\n",
    "\n",
    "\n",
    "\n",
    "# TF-IDF(document, query):\n",
    "\n",
    "# len(query(term)) is df(term if term is one word \n",
    "\n",
    "\n",
    "def tf_idf(term_freq, document_freq, collection_len):\n",
    "    if term_freq == 0 or document_freq == 0:\n",
    "        return 0\n",
    "    return (1 + math.log(term_freq)) * math.log(collection_len/document_freq)\n",
    "\n",
    "# hacer vectores de scores de documents\n",
    "\n",
    "def doc_score(doc_id, collection_index=index, collection=\"\"):\n",
    "    result={}\n",
    "    \n",
    "    collection = collection if collection else {tweet.id: tweet.full_text for tweet in tweets.itertuples(index=True)}\n",
    "    collection_len = len(collection)\n",
    "    \n",
    "    document = collection[doc_id].split(\" \")\n",
    "    term_frequencies = Counter(document)\n",
    "    \n",
    "    for term in document:\n",
    "        print(term)\n",
    "        document_freq = len(query(term, tweet_index=collection_index))\n",
    "        result[term] = tf_idf(term_frequencies[term], document_freq, collection_len)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cosine_score(query_text, collection_index=index, collection=\"\", k=10):\n",
    "               \n",
    "\n",
    "    collection = collection if collection else {tweet.id: tweet.full_text for tweet in tweets.itertuples(index=True)}\n",
    "    collection_len = len(collection)\n",
    "           \n",
    "    scores = {doc_id: 0 for doc_id in collection.keys()}\n",
    "    \n",
    "    # esto seguramente este mal\n",
    "    length = {doc_id: len(str(document).split(\" \")) for doc_id, document in collection.items()}\n",
    "    \n",
    "    query_terms = build_terms(query_text) # necessary step since same treatment applied to tweets\n",
    "    \n",
    "    # dictionary of frequency of each term in the query\n",
    "    query_frequencies = Counter(query_terms)\n",
    "        \n",
    "    for term in query_terms:\n",
    "        \n",
    "        # query of a term returns the set of documents containing the term\n",
    "        document_freq = len(query(term, tweet_index=collection_index))\n",
    "        \n",
    "        query_weight = tf_idf(query_frequencies[term], document_freq, collection_len)\n",
    "        \n",
    "        # hasta aqui esta bien probablemente, despues pasa algo raro\n",
    "        for doc_id, document in collection.items():\n",
    "            # counter of distinct terms in document\n",
    "            term_frequencies = Counter(str(document).split(\" \"))\n",
    "            document_weight = tf_idf(term_frequencies[term], document_freq, collection_len)\n",
    "            scores[doc_id] += query_weight * document_weight\n",
    "\n",
    "            \n",
    "    for doc_id, doc_len in length.items():\n",
    "        scores[doc_id] = scores[doc_id] / doc_len\n",
    "        \n",
    "    doc_ids_sorted = sorted(scores, key=scores.get, reverse=True)[:k]\n",
    "    return {doc_id: scores[doc_id] for doc_id in doc_ids_sorted}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8661e6fe-5da1-43fb-9c94-7bc5c39ac092",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8661e6fe-5da1-43fb-9c94-7bc5c39ac092",
    "outputId": "b4695260-18c2-4685-9635-9a5682905ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep\n",
      "spin\n",
      "us\n",
      "7\n",
      "pm…go\n",
      "away\n",
      "already.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keep': 3.8873303928377747,\n",
       " 'spin': 7.600902459542082,\n",
       " 'us': 3.4420193761824107,\n",
       " '7': 6.0968250627658085,\n",
       " 'pm…go': 8.294049640102028,\n",
       " 'away': 4.305065593537753,\n",
       " 'already.': 6.907755278982137}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_score(\"keep us posted\")\n",
    "doc_score(\"doc_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zcniTIFwRStU",
   "metadata": {
    "id": "zcniTIFwRStU"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4hhTKjnnSOfA",
   "metadata": {
    "id": "4hhTKjnnSOfA"
   },
   "outputs": [],
   "source": [
    "# useful functions for the evaluation\n",
    "def precision_k (y_true, y_score, k=10):\n",
    "    order = y_score.argsort()[::1]\n",
    "    y_true = y_true.take(order)\n",
    "    relevant = np.sum(y_true[:k])\n",
    "    return float(relevant/k)\n",
    "\n",
    "def recall_k (y_true, y_score, k=10):\n",
    "    order = y_score.argsort()[::1]\n",
    "    y_true = y_true.take(order)\n",
    "    relevant = np.sum(y_true[:k])\n",
    "    total_relevant = np.sum(y_true[:])\n",
    "    return float(relevant/total_relevant)\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    return (2*precision*recall)/(precision+recall)\n",
    "\n",
    "def avg_precision_at_k(doc_score, y_score, k=10):\n",
    "    gtp = np.sum(doc_score == 1)\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    doc_score = np.take(doc_score, order[:k])\n",
    "    if gtp == 0:\n",
    "        return 0\n",
    "    n_relevant_at_i = 0\n",
    "    prec_at_i = 0\n",
    "    for i in range(len(doc_score)):\n",
    "        if doc_score[i] == 1:\n",
    "            n_relevant_at_i += 1\n",
    "            prec_at_i += n_relevant_at_i / (i + 1)\n",
    "    return prec_at_i / gtp\n",
    "\n",
    "def map_at_k(search_res, k=10):\n",
    "    avp = []\n",
    "    for q in search_res[\"query_id\"].unique():\n",
    "        curr_data = search_res[search_res[\"query_id\"] == q]\n",
    "        avp.append(avg_precision_at_k(np.array(curr_data[\"label\"]), \n",
    "                   np.array(curr_data[\"doc\"]), k))\n",
    "    return np.sum(avp) / len(avp)\n",
    "\n",
    "def rr_at_k(doc_score, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    doc_score = np.take(doc_score, order[:k])\n",
    "    if np.sum(doc_score) == 0:\n",
    "        return 0\n",
    "    return 1 / (np.argmax(doc_score == 1) + 1)\n",
    "\n",
    "def dcg_at_k(doc_score, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    doc_score = np.take(doc_score, order[:k])\n",
    "    gain = 2 ** doc_score - 1\n",
    "    discounts = np.log2(np.arange(len(doc_score)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_at_k(doc_score, y_score, k=10):\n",
    "    dcg_max = dcg_at_k(doc_score, doc_score, k)\n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    return np.round(dcg_at_k(doc_score, y_score, k) / dcg_max, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vvo6nCpRRx7m",
   "metadata": {
    "id": "vvo6nCpRRx7m"
   },
   "source": [
    "#### Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "k-VfnWbARavi",
   "metadata": {
    "id": "k-VfnWbARavi"
   },
   "outputs": [],
   "source": [
    "# read the new csv file as a dataframe\n",
    "with open(f'{BASEDIR}/data/evaluation_gt.csv', 'r') as file:\n",
    "    ev_array = file.readlines()\n",
    "    ev_array = [row.rstrip().split(',') for row in ev_array]\n",
    "df_evaluation = pd.DataFrame(ev_array[1:], \n",
    "             columns=ev_array[0])\n",
    "for index, row in df_evaluation.iterrows():\n",
    "  df_evaluation['doc'][index] = int(df_evaluation['doc'][index].split(\"_\")[1])\n",
    "df_evaluation['query_id'] = pd.to_numeric(df_evaluation['query_id'])\n",
    "df_evaluation['label'] = pd.to_numeric(df_evaluation['label'])\n",
    "#df = df.set_index('doc').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "VzC5IJp5VAL3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VzC5IJp5VAL3",
    "outputId": "6dc290d8-4597-44e4-9218-522cfedfe73f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1\n",
      "==> Precision@10: 0.9\n",
      "\n",
      "==> Recall@10: 0.9\n",
      "\n",
      "==> F1score@10: 0.9\n",
      "\n",
      "==> AveragePrecision@10: 0.014285714285714285\n",
      "\n",
      "==> MAP@10: 0.02063492063492063\n",
      "\n",
      "==> RR@10: 0.14285714285714285\n",
      "\n",
      "==> NDCG@10: 0.0734\n",
      "\n",
      "Query 2\n",
      "==> Precision@10: 0.8\n",
      "\n",
      "==> Recall@10: 0.8\n",
      "\n",
      "==> F1score@10: 0.8000000000000002\n",
      "\n",
      "==> AveragePrecision@10: 0.0365079365079365\n",
      "\n",
      "==> MAP@10: 0.02063492063492063\n",
      "\n",
      "==> RR@10: 0.14285714285714285\n",
      "\n",
      "==> NDCG@10: 0.1396\n",
      "\n",
      "Query 3\n",
      "==> Precision@10: 0.9\n",
      "\n",
      "==> Recall@10: 0.9\n",
      "\n",
      "==> F1score@10: 0.9\n",
      "\n",
      "==> AveragePrecision@10: 0.01111111111111111\n",
      "\n",
      "==> MAP@10: 0.02063492063492063\n",
      "\n",
      "==> RR@10: 0.1111111111111111\n",
      "\n",
      "==> NDCG@10: 0.0663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/98/r5h7_tb55pvdx8zbc30wjdm80000gp/T/ipykernel_3082/1136003263.py:5: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  relevant = np.sum(y_true[:k])\n",
      "/var/folders/98/r5h7_tb55pvdx8zbc30wjdm80000gp/T/ipykernel_3082/1136003263.py:11: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  relevant = np.sum(y_true[:k])\n"
     ]
    }
   ],
   "source": [
    "for q in [1,2,3]:\n",
    "  current_query_res = df_evaluation[df_evaluation[\"query_id\"] == q]\n",
    "  k = 10\n",
    "  precision = precision_k(current_query_res[\"label\"], current_query_res[\"doc\"], k)\n",
    "  recall = recall_k(current_query_res[\"label\"], current_query_res[\"doc\"], k)\n",
    "  print(\"Query {}\".format(q))\n",
    "  print(\"==> Precision@{}: {}\\n\".format(k, precision))\n",
    "  print(\"==> Recall@{}: {}\\n\".format(k, recall))\n",
    "  print(\"==> F1score@{}: {}\\n\".format(k, f1_score(precision, recall)))\n",
    "  print(\"==> AveragePrecision@{}: {}\\n\".format(k, avg_precision_at_k(np.array(current_query_res[\"label\"]), np.array(current_query_res[\"doc\"]), k)))\n",
    "  print(\"==> MAP@{}: {}\\n\".format(k, map_at_k(df_evaluation, k)))\n",
    "  print(\"==> RR@{}: {}\\n\".format(k, rr_at_k(np.array(current_query_res[\"label\"]), np.array(current_query_res[\"doc\"]), k)))\n",
    "  print(\"==> NDCG@{}: {}\\n\".format(k, ndcg_at_k(np.array(current_query_res[\"label\"]), np.array(current_query_res[\"doc\"]), k)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AH_dcoduR7C7",
   "metadata": {
    "id": "AH_dcoduR7C7"
   },
   "source": [
    "#### Defined queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YQtzeaVfjyfO",
   "metadata": {
    "id": "YQtzeaVfjyfO"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_VH9QM2xSCIt",
   "metadata": {
    "id": "_VH9QM2xSCIt"
   },
   "source": [
    "### Tweet representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EFv7uwjzSHqk",
   "metadata": {
    "id": "EFv7uwjzSHqk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
