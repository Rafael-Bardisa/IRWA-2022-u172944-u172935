{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "iiB2f3Y-5eXS",
   "metadata": {
    "id": "iiB2f3Y-5eXS"
   },
   "source": [
    "# Information Retrieval and Web Analytics\n",
    "\n",
    "# Part 2: Indexing and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf6d8963-aa98-40f2-8399-94b866d9c18e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf6d8963-aa98-40f2-8399-94b866d9c18e",
    "outputId": "302ed6ae-5372-44b3-eec9-5e83a854e875"
   },
   "outputs": [],
   "source": [
    "# mount google drive if using google collab, else skip\n",
    "# we are not using it because it is more comfortable to use jupyter lab\n",
    "\n",
    "BASEDIR = '.'\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    BASEDIR = 'drive/MyDrive'\n",
    "    \n",
    "except ModuleNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2a1daf4-842d-4c00-b294-0efef0747570",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2a1daf4-842d-4c00-b294-0efef0747570",
    "outputId": "b6544122-72ef-4d0b-cecf-831928a25df6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rafaelbardisarodes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# required imports for the notebook\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "from array import array\n",
    "from collections import defaultdict, Counter\n",
    "import functools\n",
    "\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c63017f6-7ced-4d7d-b4b9-875355f082ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "RED = \"\\033[91m\"\n",
    "WHITE = \"\\033[0m\"\n",
    "\n",
    "\n",
    "def benchmark(func):\n",
    "    \"\"\"\n",
    "    Decorador que te mide el tiempo que tarda la funcion en ejecutarse.\n",
    "    Se puede usar como cualquier funcion, e.g. benchmark(func),\n",
    "    pero al ser un decorador la gracia que tiene es que al hacer\n",
    "    @benchmark\n",
    "    def func():...\n",
    "    cada vez que uses func() estaras usando benchmark(func)()\n",
    "    :param func: la funcion que quieres testear\n",
    "    :return: la funcion original envuelta por el codigo de testeo\n",
    "    \"\"\"\n",
    "    def inner(*args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.perf_counter()\n",
    "        print(f'Time taken for {RED}{func.__name__}{WHITE}: {end - start:.4f}')\n",
    "        return result\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "Iq8CBGFPEqTa",
   "metadata": {
    "id": "Iq8CBGFPEqTa"
   },
   "outputs": [],
   "source": [
    "# open results from last practice\n",
    "tweets = pd.read_csv(f'{BASEDIR}/data/processed_tweets.csv')\n",
    "tweets = tweets.reset_index()  # make sure indexes pair with number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yPqSycI3REu6",
   "metadata": {
    "id": "yPqSycI3REu6"
   },
   "source": [
    "### Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "99eKgkLSGjsB",
   "metadata": {
    "id": "99eKgkLSGjsB"
   },
   "outputs": [],
   "source": [
    "# reuse of the function shown in class to transform text into lowercase and erase stop words in queries\n",
    "def build_terms(line):\n",
    "    \"\"\"\n",
    "    Preprocess the line removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "    \n",
    "    Argument:\n",
    "    line -- string (text) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    line - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    line = line.lower()\n",
    "    line = line.split()  # Tokenize the text to get a list of terms\n",
    "    line = [x for x in line if x not in stop_words]  # eliminate the stopwords\n",
    "    line = [stemmer.stem(word) for word in line] # perform stemming (HINT: use List Comprehension)\n",
    "    return line\n",
    "\n",
    "\n",
    "@benchmark\n",
    "def create_index(tweets):\n",
    "    \"\"\"\n",
    "    Implement the inverted index\n",
    "    \n",
    "    Argument:\n",
    "    lines -- collection of Wikipedia articles\n",
    "    \n",
    "    Returns:\n",
    "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
    "    list of documents where these keys appears in (and the positions) as values.\n",
    "    \"\"\"\n",
    "    index = defaultdict(list)\n",
    "    title_index = {}  # dictionary to map page titles to page ids\n",
    "\n",
    "    for tweet in tweets.itertuples(index=True):  # Remember, lines contain all documents from file\n",
    "        tweet_text = tweet.full_text\n",
    "        \n",
    "        # tweet id\n",
    "        tweet_id = int(tweet.id.split(\"_\")[1])\n",
    "\n",
    "        terms = str(tweet_text).split(\" \")  # page_title + page_text\n",
    "\n",
    "        title_index[tweet_id] = tweet.user  ## we do not need to apply get terms to title because it used only to print titles and not in the index\n",
    "        \n",
    "        ## ===============================================================        \n",
    "        ## create the index for the current page and store it in current_page_index (current_page_index)\n",
    "        ## current_page_index ==> { ‘term1’: [current_doc, [list of positions]], ...,‘term_n’: [current_doc, [list of positions]]}\n",
    "\n",
    "        ## Example: if the curr_doc has id 1 and his text is \"web retrieval information retrieval\":\n",
    "\n",
    "        ## current_page_index ==> { ‘web’: [1, [0]], ‘retrieval’: [1, [1,4]], ‘information’: [1, [2]]}\n",
    "\n",
    "        ## the term ‘web’ appears in document 1 in positions 0, \n",
    "        ## the term ‘retrieval’ appears in document 1 in positions 1 and 4\n",
    "        ## ===============================================================\n",
    "\n",
    "        current_page_index = {}\n",
    "\n",
    "        for position, term in enumerate(terms): # terms contains page_title + page_text. Loop over all terms\n",
    "            try:\n",
    "                # if the term is already in the index for the current page (current_page_index)\n",
    "                # append the position to the corresponding list\n",
    "                current_page_index[term][1].append(position)\n",
    "            except:\n",
    "                # Add the new term as dict key and initialize the array of positions and add the position\n",
    "                current_page_index[term] = [tweet_id, array('I', [position])]  #'I' indicates unsigned int (int in Python)\n",
    "\n",
    "        # merge the current page index with the main index\n",
    "        for term_page, posting_page in current_page_index.items():\n",
    "            index[term_page].append(posting_page)\n",
    "    return index, title_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "Ib0gaZhiLvhD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "Ib0gaZhiLvhD",
    "outputId": "0d3178a9-fa67-4e9b-9d56-5e5d92ee6a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for \u001b[91mcreate_index\u001b[0m: 1.5668\n"
     ]
    }
   ],
   "source": [
    "index, title_index= create_index(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nHfVOqpgRLnc",
   "metadata": {
    "id": "nHfVOqpgRLnc"
   },
   "source": [
    "### 5 Text queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "F5aBt6wSRO_P",
   "metadata": {
    "id": "F5aBt6wSRO_P"
   },
   "outputs": [],
   "source": [
    "# def query(text)?:\n",
    "# build terms(query)\n",
    "\n",
    "# index = tremendo index\n",
    "# foreach term in query\n",
    "# index = index[term in entry] <- boolean mask, conjunctive AND\n",
    "\n",
    "# return index <- the doc ids\n",
    "# or\n",
    "# return tweets[original_text][index] <- get original text of tweets containing all elements in query\n",
    "\n",
    "def query(text, tweet_index=\"\"):\n",
    "    \"\"\"\n",
    "    search for a given text in the tweet collection using the\n",
    "    inverted index we previously computed\n",
    "    :param text: the query text\n",
    "    :param tweet_index: inverted index of the collection, named as such because context of practice\n",
    "    :return: list of tweet ids containing all (treated) terms in the query\n",
    "    \"\"\"\n",
    "    \n",
    "    # necessary step since same treatment applied to tweets\n",
    "    terms = build_terms(text)\n",
    "    \n",
    "    # select tweet index, defaults to global index but can be specified\n",
    "    tweet_index = tweet_index if tweet_index else index\n",
    "    \n",
    "    plausible_ids = []\n",
    "    for query_term in terms:\n",
    "        # tweet_index[query_term] is list of tweet ids containing query term + position(s) in text, could be useful in the future\n",
    "        # plausible_ids[query_term] = tweet_index[query_term]\n",
    "        \n",
    "        # using sets is convenient for using reduce\n",
    "        plausible_ids.append(set(term_pos[0] for term_pos in tweet_index[query_term]))\n",
    "        \n",
    "    # reduce list of sets to intersection of all\n",
    "    relevant_ids = functools.reduce(lambda a, b: a.intersection(b), plausible_ids)\n",
    "                             \n",
    "    return relevant_ids\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1f972cec-c2a7-4645-a28a-ab6a7225a533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 484, 762, 2045, 3377, 3996}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(\"keeps us\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bt_s1CwPRPmt",
   "metadata": {
    "id": "Bt_s1CwPRPmt"
   },
   "source": [
    "### Ranking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "M-z_0onURSJX",
   "metadata": {
    "id": "M-z_0onURSJX"
   },
   "outputs": [],
   "source": [
    "# rank(query):\n",
    "# query = build_terms(query)\n",
    "\n",
    "# scores = {}\n",
    "# length = {}\n",
    "# foreach term in query:\n",
    "# w_q = TF-IDF(term, query), docids = query(term)\n",
    "# foreach docid in docids:\n",
    "# scores[docid] += TF-IDF(term, tweets.full_text[docid]) * w_q\n",
    "# ::\n",
    "# foreach docid:\n",
    "# scores[d] /= len(tweets.full_text[docid])\n",
    "\n",
    "# sort scores, return top K\n",
    "\n",
    "\n",
    "# relevant documents = query(query)\n",
    "# foreach document in relevant_documents\n",
    "# TF-IDF(document, query)\n",
    "\n",
    "\n",
    "\n",
    "# TF-IDF(document, query):\n",
    "\n",
    "# len(query(term)) is df(term if term is one word \n",
    "\n",
    "\n",
    "def tf_idf(term_freq, document_freq, collection_len):\n",
    "    if term_freq == 0 or document_freq == 0:\n",
    "        return 0\n",
    "    return (1 + math.log(term_freq)) * math.log(collection_len/document_freq)\n",
    "\n",
    "\n",
    "def cosine_score(query_text, collection_index=\"\", collection=\"\", k=10):\n",
    "               \n",
    "    collection_index = collection_index if collection_index else index\n",
    "    collection = collection if collection else {tweet.id: tweet.full_text for tweet in tweets.itertuples(index=True)}\n",
    "    collection_len = len(collection)\n",
    "           \n",
    "    scores = {doc_id: 0 for doc_id in collection.keys()}\n",
    "    length = {doc_id: len(str(document).split(\" \")) for doc_id, document in collection.items()}\n",
    "    \n",
    "    query_terms = build_terms(query_text) # necessary step since same treatment applied to tweets\n",
    "    \n",
    "    # dictionary of frequency of each term in the query\n",
    "    query_frequencies = Counter(query_terms)\n",
    "        \n",
    "    for term in query_terms:\n",
    "        \n",
    "        # query of a term returns the set of documents containing the term\n",
    "        document_freq = len(query(term, tweet_index=collection_index))\n",
    "        \n",
    "        query_weight = tf_idf(query_frequencies[term], document_freq, collection_len)\n",
    "        \n",
    "        # hasta aqui esta bien probablemente, despues pasa algo raro\n",
    "        for doc_id, document in collection.items():\n",
    "            # counter of distinct terms in document\n",
    "            term_frequencies = Counter(str(document).split(\" \"))\n",
    "            document_weight = tf_idf(term_frequencies[term], document_freq, collection_len)\n",
    "            scores[doc_id] += query_weight * document_weight\n",
    "\n",
    "            \n",
    "    for doc_id, doc_len in length.items():\n",
    "        scores[doc_id] = scores[doc_id] / doc_len\n",
    "        \n",
    "    doc_ids_sorted = sorted(scores, key=scores.get, reverse=True)[:k]\n",
    "    return {doc_id: scores[doc_id] for doc_id in doc_ids_sorted}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8661e6fe-5da1-43fb-9c94-7bc5c39ac092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_1069': 7.227550714690679,\n",
       " 'doc_433': 6.396429655820483,\n",
       " 'doc_1873': 5.420663036018009,\n",
       " 'doc_3377': 5.391766993819088,\n",
       " 'doc_1320': 5.037112527693429,\n",
       " 'doc_2677': 5.037112527693429,\n",
       " 'doc_1546': 4.336530428814408,\n",
       " 'doc_1': 3.8512621384422054,\n",
       " 'doc_2640': 3.6137753573453395,\n",
       " 'doc_3175': 2.5185562638467145}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_score(\"keep us posted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zcniTIFwRStU",
   "metadata": {
    "id": "zcniTIFwRStU"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4hhTKjnnSOfA",
   "metadata": {
    "id": "4hhTKjnnSOfA"
   },
   "outputs": [],
   "source": [
    "# useful functions for the evaluation\n",
    "def precision_k (y_true, y_score, k=10):\n",
    "    order = y_score.argsort()[::-1]\n",
    "    y_true = y_true.take(order)\n",
    "    relevant = np.sum(y_true[:k])\n",
    "    return float(relevant/k)\n",
    "\n",
    "def recall_k (y_true, y_score, k=10):\n",
    "    order = y_score.argsort()[::-1]\n",
    "    y_true = y_true.take(order)\n",
    "    relevant = np.sum(y_true[:k])\n",
    "    total_relevant = np.sum(y_true[:])\n",
    "    return float(relevant/total_relevant)\n",
    "\n",
    "def f1_score(precision, recall):\n",
    "    return (2*precision*recall)/(precision+recall)\n",
    "\n",
    "def avg_precision_at_k(doc_score, y_score, k=10):\n",
    "    gtp = np.sum(doc_score == 1)\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    doc_score = np.take(doc_score, order[:k])\n",
    "    if gtp == 0:\n",
    "        return 0\n",
    "    n_relevant_at_i = 0\n",
    "    prec_at_i = 0\n",
    "    for i in range(len(doc_score)):\n",
    "        if doc_score[i] == 1:\n",
    "            n_relevant_at_i += 1\n",
    "            prec_at_i += n_relevant_at_i / (i + 1)\n",
    "    return prec_at_i / gtp\n",
    "\n",
    "def map_at_k(search_res, k=10):\n",
    "    avp = []\n",
    "    for q in search_res[\"query_id\"].unique():\n",
    "        curr_data = search_res[search_res[\"query_id\"] == q]\n",
    "        avp.append(avg_precision_at_k(np.array(curr_data[\"is_relevant\"]), \n",
    "                   np.array(curr_data[\"predicted_relevance\"]), k))\n",
    "    return np.sum(avp) / len(avp), avp\n",
    "\n",
    "def rr_at_k(doc_score, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    doc_score = np.take(doc_score, order[:k])\n",
    "    if np.sum(doc_score) == 0:\n",
    "        return 0\n",
    "    return 1 / (np.argmax(doc_score == 1) + 1)\n",
    "\n",
    "def dcg_at_k(doc_score, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    doc_score = np.take(doc_score, order[:k])\n",
    "    gain = 2 ** doc_score - 1\n",
    "    discounts = np.log2(np.arange(len(doc_score)) + 2)\n",
    "    return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_at_k(doc_score, y_score, k=10):\n",
    "    dcg_max = dcg_at_k(doc_score, doc_score, k)\n",
    "    if not dcg_max:\n",
    "        return 0\n",
    "    return np.round(dcg_at_k(doc_score, y_score, k) / dcg_max, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vvo6nCpRRx7m",
   "metadata": {
    "id": "vvo6nCpRRx7m"
   },
   "source": [
    "#### Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "k-VfnWbARavi",
   "metadata": {
    "id": "k-VfnWbARavi"
   },
   "outputs": [],
   "source": [
    "# read the new csv file as a dataframe\n",
    "with open(f'{BASEDIR}/data/evaluation_gt.csv', 'r') as file:\n",
    "    ev_array = file.readlines()\n",
    "    ev_array = [row.rstrip().split(',') for row in ev_array]\n",
    "df = pd.DataFrame(ev_array[1:], \n",
    "             columns=[ev_array[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "VzC5IJp5VAL3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "VzC5IJp5VAL3",
    "outputId": "4860c8fa-c0bc-460a-94d3-95a0eac0e126"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-8b0a7e762116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcurrent_query_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==> Precision@{}: {}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_query_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_query_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-94-8580c6c30f2d>\u001b[0m in \u001b[0;36mprecision_k\u001b[0;34m(y_true, y_score, k)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# useful functions for the evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprecision_k\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrelevant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'argsort'"
     ]
    }
   ],
   "source": [
    "current_query_res = df[df[\"query_id\"] == 0]\n",
    "k = 10\n",
    "print(\"==> Precision@{}: {}\\n\".format(k, precision_k(current_query_res[\"label\"], current_query_res[\"label\"], k)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AH_dcoduR7C7",
   "metadata": {
    "id": "AH_dcoduR7C7"
   },
   "source": [
    "#### Defined queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "t7mRdwfQRgI7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "t7mRdwfQRgI7",
    "outputId": "943a88cc-c890-491d-eefb-660097d2d4a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e69473b5-9d29-4088-81a1-b620de343207\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>query_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doc_12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc_9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doc_18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>doc_45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>doc_501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>doc_52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>doc_82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>doc_100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>doc_122</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>doc_165</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>doc_158</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>doc_175</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>doc_268</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>doc_303</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>doc_321</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>doc_358</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>doc_373</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>doc_402</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>doc_453</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>doc_504</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>doc_30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>doc_65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>doc_66</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>doc_112</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>doc_148</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>doc_150</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>doc_198</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>doc_370</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>doc_30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>doc_65</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>doc_125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>doc_306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>doc_441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>doc_494</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>doc_525</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>doc_1002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>doc_1076</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>doc_1096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>doc_1195</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>doc_1233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>doc_125</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>doc_306</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>doc_441</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>doc_494</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>doc_525</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>doc_1002</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>doc_1076</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>doc_1096</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>doc_1195</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>doc_1233</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>doc_125</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>doc_306</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>doc_441</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>doc_494</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>doc_525</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>doc_1002</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>doc_1076</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>doc_1096</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>doc_1195</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>doc_1233</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e69473b5-9d29-4088-81a1-b620de343207')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e69473b5-9d29-4088-81a1-b620de343207 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e69473b5-9d29-4088-81a1-b620de343207');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         doc query_id label\n",
       "0     doc_12        1     1\n",
       "1      doc_9        1     1\n",
       "2     doc_18        1     1\n",
       "3     doc_45        1     1\n",
       "4    doc_501        1     1\n",
       "5     doc_52        1     1\n",
       "6     doc_82        1     1\n",
       "7    doc_100        1     1\n",
       "8    doc_122        1     1\n",
       "9    doc_165        1     1\n",
       "10   doc_158        2     1\n",
       "11   doc_175        2     1\n",
       "12   doc_268        2     1\n",
       "13   doc_303        2     1\n",
       "14   doc_321        2     1\n",
       "15   doc_358        2     1\n",
       "16   doc_373        2     1\n",
       "17   doc_402        2     1\n",
       "18   doc_453        2     1\n",
       "19   doc_504        2     1\n",
       "20    doc_30        3     1\n",
       "21    doc_65        3     1\n",
       "22    doc_66        3     1\n",
       "23   doc_112        3     1\n",
       "24   doc_148        3     1\n",
       "25   doc_150        3     1\n",
       "26   doc_198        3     1\n",
       "27   doc_370        3     1\n",
       "28    doc_30        3     1\n",
       "29    doc_65        3     1\n",
       "30   doc_125        1     0\n",
       "31   doc_306        1     0\n",
       "32   doc_441        1     0\n",
       "33   doc_494        1     0\n",
       "34   doc_525        1     0\n",
       "35  doc_1002        1     0\n",
       "36  doc_1076        1     0\n",
       "37  doc_1096        1     0\n",
       "38  doc_1195        1     0\n",
       "39  doc_1233        1     0\n",
       "40   doc_125        2     0\n",
       "41   doc_306        2     0\n",
       "42   doc_441        2     0\n",
       "43   doc_494        2     0\n",
       "44   doc_525        2     0\n",
       "45  doc_1002        2     0\n",
       "46  doc_1076        2     0\n",
       "47  doc_1096        2     0\n",
       "48  doc_1195        2     0\n",
       "49  doc_1233        2     0\n",
       "50   doc_125        3     0\n",
       "51   doc_306        3     0\n",
       "52   doc_441        3     0\n",
       "53   doc_494        3     0\n",
       "54   doc_525        3     0\n",
       "55  doc_1002        3     0\n",
       "56  doc_1076        3     0\n",
       "57  doc_1096        3     0\n",
       "58  doc_1195        3     0\n",
       "59  doc_1233        3     0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_VH9QM2xSCIt",
   "metadata": {
    "id": "_VH9QM2xSCIt"
   },
   "source": [
    "### Tweet representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EFv7uwjzSHqk",
   "metadata": {
    "id": "EFv7uwjzSHqk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
