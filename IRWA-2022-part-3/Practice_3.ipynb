{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "iiB2f3Y-5eXS",
      "metadata": {
        "id": "iiB2f3Y-5eXS"
      },
      "source": [
        "# Information Retrieval and Web Analytics\n",
        "\n",
        "# Part 3: Ranking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cf6d8963-aa98-40f2-8399-94b866d9c18e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf6d8963-aa98-40f2-8399-94b866d9c18e",
        "outputId": "52fca2db-aa3c-4416-abc3-88b25033b69f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount google drive if using google collab, else skip\n",
        "# we are not using it because it is more comfortable to use jupyter lab\n",
        "\n",
        "BASEDIR = '.'\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    BASEDIR = 'drive/MyDrive'\n",
        "    \n",
        "except ModuleNotFoundError:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e2a1daf4-842d-4c00-b294-0efef0747570",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2a1daf4-842d-4c00-b294-0efef0747570",
        "outputId": "8e11851a-1fa3-4863-da63-580136e57179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# required imports for the notebook\n",
        "\n",
        "import json\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "from array import array\n",
        "from collections import defaultdict, Counter\n",
        "import functools\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "import rank_bm25\n",
        "\n",
        "\n",
        "# queries for testing\n",
        "queries = [\n",
        "    \"keep us posted\",\n",
        "    \"ian update\",\n",
        "    \"disney world\",\n",
        "    \"climate change\",\n",
        "    \"hit state\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "Iq8CBGFPEqTa",
      "metadata": {
        "id": "Iq8CBGFPEqTa"
      },
      "outputs": [],
      "source": [
        "# open results from last practice\n",
        "tweets = pd.read_csv(f'{BASEDIR}/data/processed_tweets.csv')\n",
        "tweets = tweets.reset_index()  # make sure indexes pair with number of rows"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yPqSycI3REu6",
      "metadata": {
        "id": "yPqSycI3REu6"
      },
      "source": [
        "### Content from practice part 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "RED = \"\\033[91m\"\n",
        "WHITE = \"\\033[0m\"\n",
        "\n",
        "\n",
        "def benchmark(func):\n",
        "    \"\"\"\n",
        "    Decorador que te mide el tiempo que tarda la funcion en ejecutarse.\n",
        "    Se puede usar como cualquier funcion, e.g. benchmark(func),\n",
        "    pero al ser un decorador la gracia que tiene es que al hacer\n",
        "    @benchmark\n",
        "    def func():...\n",
        "    cada vez que uses func() estaras usando benchmark(func)()\n",
        "    :param func: la funcion que quieres testear\n",
        "    :return: la funcion original envuelta por el codigo de testeo\n",
        "    \"\"\"\n",
        "    def inner(*args, **kwargs):\n",
        "        start = time.perf_counter()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.perf_counter()\n",
        "        print(f'Time taken for {RED}{func.__name__}{WHITE}: {end - start:.4f}')\n",
        "        return result\n",
        "\n",
        "    return inner\n",
        "\n",
        "def remove_punctuation(text):\n",
        "\n",
        "    \"\"\"\n",
        "    Removes the characters:\n",
        "    !\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~0123456789\n",
        "    from the text.\n",
        "    \"\"\"\n",
        "\n",
        "    chars_to_remove = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~0123456789\"\n",
        "\n",
        "    tr = str.maketrans(\"\", \"\", chars_to_remove)\n",
        "\n",
        "    return text.translate(tr)"
      ],
      "metadata": {
        "id": "WZ4Atzt9Xf4A"
      },
      "id": "WZ4Atzt9Xf4A",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "99eKgkLSGjsB",
      "metadata": {
        "id": "99eKgkLSGjsB"
      },
      "outputs": [],
      "source": [
        "# reuse of the function shown in class to transform text into lowercase and erase stop words in queries\n",
        "def build_terms(line):\n",
        "    \"\"\"\n",
        "    Preprocess the line removing stop words, stemming,\n",
        "    transforming in lowercase and return the tokens of the text.\n",
        "    \n",
        "    Argument:\n",
        "    line -- string (text) to be preprocessed\n",
        "    \n",
        "    Returns:\n",
        "    line - a list of tokens corresponding to the input text after the preprocessing\n",
        "    \"\"\"\n",
        "\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    line = str(line).lower()\n",
        "    \n",
        "    # tremendo pero aligual rompe algo despues\n",
        "    line = remove_punctuation(line)\n",
        "    \n",
        "    line = line.split()  # Tokenize the text to get a list of terms\n",
        "    line = [x for x in line if x not in stop_words]  # eliminate the stopwords\n",
        "    line = [stemmer.stem(word) for word in line] # perform stemming (HINT: use List Comprehension)\n",
        "    return line\n",
        "\n",
        "\n",
        "@benchmark\n",
        "def create_index(tweets):\n",
        "    \"\"\"\n",
        "    Implement the inverted index\n",
        "    \n",
        "    Argument:\n",
        "    lines -- collection of Wikipedia articles\n",
        "    \n",
        "    Returns:\n",
        "    index - the inverted index (implemented through a Python dictionary) containing terms as keys and the corresponding\n",
        "    list of documents where these keys appears in (and the positions) as values.\n",
        "    \"\"\"\n",
        "    index = defaultdict(list)\n",
        "    title_index = {}  # dictionary to map page titles to page ids\n",
        "\n",
        "    for tweet in tweets.itertuples(index=True):  # Remember, lines contain all documents from file\n",
        "        tweet_text = tweet.full_text\n",
        "        \n",
        "        # tweet id\n",
        "        tweet_id = int(tweet.id.split(\"_\")[1])\n",
        "\n",
        "        terms = str(tweet_text).split(\" \")  # page_title + page_text\n",
        "\n",
        "        title_index[tweet_id] = tweet.user  ## we do not need to apply get terms to title because it used only to print titles and not in the index\n",
        "        \n",
        "        ## ===============================================================        \n",
        "        ## create the index for the current page and store it in current_page_index (current_page_index)\n",
        "        ## current_page_index ==> { ‘term1’: [current_doc, [list of positions]], ...,‘term_n’: [current_doc, [list of positions]]}\n",
        "\n",
        "        ## Example: if the curr_doc has id 1 and his text is \"web retrieval information retrieval\":\n",
        "\n",
        "        ## current_page_index ==> { ‘web’: [1, [0]], ‘retrieval’: [1, [1,4]], ‘information’: [1, [2]]}\n",
        "\n",
        "        ## the term ‘web’ appears in document 1 in positions 0, \n",
        "        ## the term ‘retrieval’ appears in document 1 in positions 1 and 4\n",
        "        ## ===============================================================\n",
        "\n",
        "        current_page_index = {}\n",
        "\n",
        "        for position, term in enumerate(terms): # terms contains page_title + page_text. Loop over all terms\n",
        "            try:\n",
        "                # if the term is already in the index for the current page (current_page_index)\n",
        "                # append the position to the corresponding list\n",
        "                current_page_index[term][1].append(position)\n",
        "            except:\n",
        "                # Add the new term as dict key and initialize the array of positions and add the position\n",
        "                current_page_index[term] = [tweet_id, array('I', [position])]  #'I' indicates unsigned int (int in Python)\n",
        "\n",
        "        # merge the current page index with the main index\n",
        "        for term_page, posting_page in current_page_index.items():\n",
        "            index[term_page].append(posting_page)\n",
        "    return index, title_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "Ib0gaZhiLvhD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ib0gaZhiLvhD",
        "outputId": "5f30bc8e-2b32-425a-cc7a-d73745abe1c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for \u001b[91mcreate_index\u001b[0m: 0.2927\n"
          ]
        }
      ],
      "source": [
        "index, title_index= create_index(tweets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nHfVOqpgRLnc",
      "metadata": {
        "id": "nHfVOqpgRLnc"
      },
      "source": [
        "### 5 Text queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "F5aBt6wSRO_P",
      "metadata": {
        "id": "F5aBt6wSRO_P"
      },
      "outputs": [],
      "source": [
        "# def query(text)?:\n",
        "# build terms(query)\n",
        "\n",
        "# index = tremendo index\n",
        "# foreach term in query\n",
        "# index = index[term in entry] <- boolean mask, conjunctive AND\n",
        "\n",
        "# return index <- the doc ids\n",
        "# or\n",
        "# return tweets[original_text][index] <- get original text of tweets containing all elements in query\n",
        "\n",
        "def query(text, tweet_index=\"\"):\n",
        "    \"\"\"\n",
        "    search for a given text in the tweet collection using the\n",
        "    inverted index we previously computed\n",
        "    :param text: the query text\n",
        "    :param tweet_index: inverted index of the collection, named as such because context of practice\n",
        "    :return: list of tweet ids containing all (treated) terms in the query\n",
        "    \"\"\"\n",
        "    \n",
        "    # necessary step since same treatment applied to tweets\n",
        "    terms = build_terms(text)\n",
        "    \n",
        "    # select tweet index, defaults to global index but can be specified\n",
        "    tweet_index = tweet_index if tweet_index else index\n",
        "    \n",
        "    plausible_ids = []\n",
        "    for query_term in terms:\n",
        "        # tweet_index[query_term] is list of tweet ids containing query term + position(s) in text, could be useful in the future\n",
        "        # plausible_ids[query_term] = tweet_index[query_term]\n",
        "        \n",
        "        # using sets is convenient for using reduce\n",
        "        plausible_ids.append(set(term_pos[0] for term_pos in tweet_index[query_term]))\n",
        "        \n",
        "    # reduce list of sets to intersection of all\n",
        "    relevant_ids = functools.reduce(lambda a, b: a.intersection(b), plausible_ids) if plausible_ids else []\n",
        "                             \n",
        "    return relevant_ids\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Bt_s1CwPRPmt",
      "metadata": {
        "id": "Bt_s1CwPRPmt"
      },
      "source": [
        "### Ranking results: TF-IDF + cosine score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "M-z_0onURSJX",
      "metadata": {
        "id": "M-z_0onURSJX"
      },
      "outputs": [],
      "source": [
        "# rank(query):\n",
        "# query = build_terms(query)\n",
        "\n",
        "# scores = {}\n",
        "# length = {}\n",
        "# foreach term in query:\n",
        "# w_q = TF-IDF(term, query), docids = query(term)\n",
        "# foreach docid in docids:\n",
        "# scores[docid] += TF-IDF(term, tweets.full_text[docid]) * w_q\n",
        "# ::\n",
        "# foreach docid:\n",
        "# scores[d] /= len(tweets.full_text[docid])\n",
        "\n",
        "# sort scores, return top K\n",
        "\n",
        "\n",
        "# relevant documents = query(query)\n",
        "# foreach document in relevant_documents\n",
        "# TF-IDF(document, query)\n",
        "\n",
        "\n",
        "\n",
        "# TF-IDF(document, query):\n",
        "\n",
        "# len(query(term)) is df(term) if term is one word \n",
        "\n",
        "\n",
        "def tf_idf(term_freq, document_freq, collection_len):\n",
        "    if term_freq == 0 or document_freq == 0:\n",
        "        return 0\n",
        "    return (1 + math.log(term_freq)) * math.log(collection_len/document_freq)\n",
        "\n",
        "\n",
        "def doc_score(doc_id, collection_index=index, collection=\"\"):\n",
        "    \"\"\"\n",
        "    vector de scores para el documento dado, es lo que hay que usar para\n",
        "    la document length\n",
        "    \n",
        "    tremendo usarlo como {doc_id: doc_score(doc_id)} para todos los ids\n",
        "    :param doc_id: document id que mirar\n",
        "    :params: se supone que así será más flexible pero los defaults van finos asi que na\n",
        "    :return: diccionario de terms y pesos, util para normalizar documentos\n",
        "    \"\"\"\n",
        "    result={}\n",
        "    \n",
        "    collection = collection if collection else {tweet.id: tweet.full_text for tweet in tweets.itertuples(index=True)}\n",
        "    collection_len = len(collection)\n",
        "    \n",
        "    document = str(collection[doc_id]).split(\" \")\n",
        "    term_frequencies = Counter(document)\n",
        "    \n",
        "    for term in document:\n",
        "        document_freq = len(query(term, tweet_index=collection_index))\n",
        "        result[term] = tf_idf(term_frequencies[term], document_freq, collection_len)\n",
        "    return result\n",
        "\n",
        "\n",
        "@benchmark\n",
        "def collection_vectors(collection=\"\", collection_index=index):\n",
        "    \"\"\"\n",
        "    multi diccionario de documentos, terms y sus valores tf-idf\n",
        "    \"\"\"\n",
        "    document_vectors = {}\n",
        "    \n",
        "    collection = collection if collection else {tweet.id: tweet.full_text for tweet in tweets.itertuples(index=True)}\n",
        "    for doc_id, document in collection.items():\n",
        "        document_vectors[doc_id] = doc_score(doc_id, collection_index=collection_index, collection=collection)\n",
        "        \n",
        "    return document_vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8661e6fe-5da1-43fb-9c94-7bc5c39ac092",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8661e6fe-5da1-43fb-9c94-7bc5c39ac092",
        "outputId": "ae31c0bf-bb66-4528-add9-e907540e5ee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for \u001b[91mcollection_vectors\u001b[0m: 23.6884\n"
          ]
        }
      ],
      "source": [
        "document_lengths = collection_vectors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "864deed3-aaba-4ce4-a347-d1d97a3c2f6b",
      "metadata": {
        "id": "864deed3-aaba-4ce4-a347-d1d97a3c2f6b"
      },
      "outputs": [],
      "source": [
        "def cosine_score(query_text, collection_index=index, collection=\"\", lengths=document_lengths, k=10):\n",
        "    \"\"\"\n",
        "    computes cosine score of all documents in a collection against a query and ranks them\n",
        "    accordingly\n",
        "    \"\"\"\n",
        "\n",
        "    collection = collection if collection else {tweet.id: tweet.full_text for tweet in tweets.itertuples(index=True)}\n",
        "    collection_len = len(collection)\n",
        "           \n",
        "    scores = {doc_id: 0 for doc_id in collection.keys()}\n",
        "    \n",
        "    # esto seguramente este mal\n",
        "    # length = {doc_id: len(str(document).split(\" \")) for doc_id, document in collection.items()}\n",
        "    \n",
        "    query_terms = build_terms(query_text) # necessary step since same treatment applied to tweets\n",
        "    \n",
        "    # dictionary of frequency of each term in the query\n",
        "    query_frequencies = Counter(query_terms)\n",
        "    \n",
        "    for term in query_terms:\n",
        "        # query of a term returns the set of documents containing the term\n",
        "        document_freq = len(query(term, tweet_index=collection_index))\n",
        "        \n",
        "        query_weight = tf_idf(query_frequencies[term], document_freq, collection_len)\n",
        "        \n",
        "        \"\"\"\n",
        "        for term in query_terms:\n",
        "        \n",
        "        # query of a term returns the set of documents containing the term\n",
        "        document_freq = len(query(term, tweet_index=collection_index))\n",
        "        \n",
        "        query_weight = tf_idf(query_frequencies[term], document_freq, collection_len)\n",
        "        \n",
        "        # hasta aqui esta bien probablemente, despues pasa algo raro\n",
        "        for doc_id, document in collection.items():\n",
        "            # counter of distinct terms in document\n",
        "            term_frequencies = Counter(str(document).split(\" \"))\n",
        "            document_weight = tf_idf(term_frequencies[term], document_freq, collection_len)\n",
        "            scores[doc_id] += query_weight * document_weight\n",
        "        \"\"\"\n",
        "            \n",
        "        for doc_id, document in collection.items():\n",
        "\n",
        "            term_frequencies = Counter(str(document).split(\" \"))\n",
        "            document_weight = tf_idf(term_frequencies[term], document_freq, collection_len)\n",
        "\n",
        "            doc_vec = list(lengths[doc_id].values())\n",
        "            scores[doc_id] = query_weight * document_weight\n",
        "            \n",
        "    scores = {doc_id: score/np.linalg.norm(list(lengths[doc_id].values())) for doc_id, score in scores.items()}\n",
        "        \n",
        "    # if k is 0 return whole doc id list\n",
        "    k = k if k else collection_len\n",
        "    \n",
        "    doc_ids_sorted = sorted(scores, key=scores.get, reverse=True)[:k]\n",
        "    return {doc_id: scores[doc_id] for doc_id in doc_ids_sorted}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8a79577f-c970-41f3-a9cc-5827a12d17f1",
      "metadata": {
        "id": "8a79577f-c970-41f3-a9cc-5827a12d17f1",
        "outputId": "c528566d-3732-456c-b920-1f42695e1f84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f7d4e96575f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mcosine_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcosine_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcosine_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcosine_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keep us\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e20e2eb008d9>\u001b[0m in \u001b[0;36mcosine_score\u001b[0;34m(query_text, collection_index, collection, lengths, k)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_terms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# query of a term returns the set of documents containing the term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdocument_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mquery_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_idf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_frequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ],
      "source": [
        "for query in queries:\n",
        "  cosine_scores = {cosine_id: score for cosine_id, score in cosine_score(query).items()}\n",
        "  print(query)\n",
        "  print(cosine_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X2iI5vlIpVxT",
      "metadata": {
        "id": "X2iI5vlIpVxT"
      },
      "source": [
        "### Ranking results: our score + cosine similarity "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5eabbafc-d1de-4a93-9cc8-a065f092336a",
      "metadata": {
        "id": "5eabbafc-d1de-4a93-9cc8-a065f092336a"
      },
      "outputs": [],
      "source": [
        "def our_score(query_text, collection_index=index, lengths=document_lengths, k=10):\n",
        "    \"\"\"\n",
        "    uhh multiply tf idf score by log popularity of tweet so our ranking is sensitive to tweet popularity\n",
        "    \"\"\"\n",
        "    tweet_data = [(tweet.id, tweet.full_text, tweet.retweet_count + tweet.favorite_count + 1) for tweet in tweets.itertuples(index=True)]\n",
        "    \n",
        "    collection = {tweet_id: text for tweet_id, text, _ in tweet_data}\n",
        "    \n",
        "    score_factor = {tweet_id: np.log10(pop_value) for tweet_id, _, pop_value in tweet_data}\n",
        "    \n",
        "    # tf-idf and cosine score\n",
        "    base_score = cosine_score(query_text, collection_index=index, collection=collection, lengths=document_lengths, k=0)\n",
        "\n",
        "    # get new scores by multiplying tf idf by tweet popularity\n",
        "    scores = {tweet_id: score * score_factor[tweet_id] for tweet_id, score in base_score.items()}\n",
        "    tweet_ids_sorted = sorted(scores, key=scores.get, reverse=True)[:k]\n",
        "    return {tweet_id: scores[tweet_id] for tweet_id in tweet_ids_sorted}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "326befbc-2abc-42b3-9fe4-dc645ef5dfea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "326befbc-2abc-42b3-9fe4-dc645ef5dfea",
        "outputId": "ac0614ae-00ab-4711-f2d4-6bbad1826667"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1405954450e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mcustom_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcustom_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcustom_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mour_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-cc894eaea0f8>\u001b[0m in \u001b[0;36mour_score\u001b[0;34m(query_text, collection_index, lengths, k)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# tf-idf and cosine score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mbase_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocument_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# get new scores by multiplying tf idf by tweet popularity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-e20e2eb008d9>\u001b[0m in \u001b[0;36mcosine_score\u001b[0;34m(query_text, collection_index, collection, lengths, k)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery_terms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# query of a term returns the set of documents containing the term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdocument_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mquery_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_idf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_frequencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
          ]
        }
      ],
      "source": [
        "for query in queries:\n",
        "  custom_scores = {custom_id: score for custom_id, score in our_score(query).items()}\n",
        "  print(query)\n",
        "  print(custom_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0F_YMqzipb8J",
      "metadata": {
        "id": "0F_YMqzipb8J"
      },
      "source": [
        "### Ranking results: BM25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "3Jd9DRieqJMZ",
      "metadata": {
        "id": "3Jd9DRieqJMZ"
      },
      "outputs": [],
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "corpus = [\n",
        "    \"Hello there good man!\",\n",
        "    \"It is quite windy in London\",\n",
        "    \"How is the weather today?\"\n",
        "]\n",
        "\n",
        "bm_collection = {tweet.id: build_terms(tweet.full_text) for tweet in tweets.itertuples(index=True)}\n",
        "bm_docs = bm_collection.values()\n",
        "#bm_collection = [build_terms(tweet.full_text) for tweet in tweets.itertuples(index=True)]\n",
        "\n",
        "bm25 = BM25Okapi(bm_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5ed50664-0c3e-4716-9753-469f0f84f926",
      "metadata": {
        "id": "5ed50664-0c3e-4716-9753-469f0f84f926",
        "outputId": "5fc4a3ea-f1d9-4303-a334-32f3a297825c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "keep us posted\n",
            "doc_3377\n",
            "doc_1\n",
            "doc_433\n",
            "doc_2160\n",
            "doc_1069\n",
            "doc_3955\n",
            "doc_2045\n",
            "doc_866\n",
            "doc_1873\n",
            "doc_2384\n",
            "doc_1546\n",
            "doc_2677\n",
            "doc_1320\n",
            "doc_3996\n",
            "doc_2495\n",
            "doc_2640\n",
            "doc_2330\n",
            "doc_2925\n",
            "doc_1187\n",
            "doc_3700\n",
            "\n",
            "ian update\n",
            "doc_1933\n",
            "doc_117\n",
            "doc_117\n",
            "doc_117\n",
            "doc_117\n",
            "doc_117\n",
            "doc_2316\n",
            "doc_2340\n",
            "doc_2249\n",
            "doc_1771\n",
            "doc_1907\n",
            "doc_344\n",
            "doc_1830\n",
            "doc_1830\n",
            "doc_1244\n",
            "doc_1244\n",
            "doc_3242\n",
            "doc_2105\n",
            "doc_460\n",
            "doc_1861\n",
            "\n",
            "disney world\n",
            "doc_3875\n",
            "doc_3029\n",
            "doc_3850\n",
            "doc_808\n",
            "doc_3397\n",
            "doc_3424\n",
            "doc_1614\n",
            "doc_2833\n",
            "doc_3795\n",
            "doc_889\n",
            "doc_2643\n",
            "doc_420\n",
            "doc_1222\n",
            "doc_1567\n",
            "doc_2821\n",
            "doc_804\n",
            "doc_3076\n",
            "doc_675\n",
            "doc_2218\n",
            "doc_3407\n",
            "\n",
            "climate change\n",
            "doc_3668\n",
            "doc_511\n",
            "doc_1958\n",
            "doc_3945\n",
            "doc_147\n",
            "doc_889\n",
            "doc_3745\n",
            "doc_1682\n",
            "doc_3661\n",
            "doc_220\n",
            "doc_1527\n",
            "doc_3469\n",
            "doc_238\n",
            "doc_2506\n",
            "doc_925\n",
            "doc_3162\n",
            "doc_2845\n",
            "doc_802\n",
            "doc_2497\n",
            "doc_3622\n",
            "\n",
            "hit state\n",
            "doc_481\n",
            "doc_842\n",
            "doc_45\n",
            "doc_2947\n",
            "doc_1973\n",
            "doc_1525\n",
            "doc_2692\n",
            "doc_665\n",
            "doc_1918\n",
            "doc_1695\n",
            "doc_2155\n",
            "doc_1482\n",
            "doc_1482\n",
            "doc_1258\n",
            "doc_924\n",
            "doc_3635\n",
            "doc_2001\n",
            "doc_988\n",
            "doc_231\n",
            "doc_2035\n"
          ]
        }
      ],
      "source": [
        "for query in queries:\n",
        "  print(\"\\n\"+query)\n",
        "  retrieved_docs = bm25.get_top_n(build_terms(query), list(bm_collection.values()), n=20)\n",
        "\n",
        "  bm_doc_ids = bm_collection.keys()\n",
        "\n",
        "  # bm uses int indexes so we must return them to normal here\n",
        "  bm_doc_retrieved_ids = [list(bm_doc_ids)[list(bm_docs).index(doc)] for doc in retrieved_docs]\n",
        "\n",
        "  for doc in retrieved_docs:\n",
        "      # print(f\"{RED}{list(bm_doc_ids)[list(bm_docs).index(doc)]}:{WHITE}\\t{doc}\")\n",
        "      print(list(bm_doc_ids)[list(bm_docs).index(doc)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeA3-ZexrDC2",
      "metadata": {
        "id": "aeA3-ZexrDC2"
      },
      "source": [
        "### Top-20 list of documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "6d94a59c-c55e-4842-a577-d3bbce7f1076",
      "metadata": {
        "id": "6d94a59c-c55e-4842-a577-d3bbce7f1076",
        "outputId": "dba3990b-d61f-42b9-c2c9-32b2a4d6bbb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a037f4f29107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtop_20_bm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbm_doc_retrieved_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtop_20_custom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtop_20_cosine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'custom_scores' is not defined"
          ]
        }
      ],
      "source": [
        "top_20_bm = tweets[tweets[\"id\"].isin(bm_doc_retrieved_ids)]\n",
        "top_20_custom = tweets[tweets[\"id\"].isin(custom_scores.keys())]\n",
        "top_20_cosine = tweets[tweets[\"id\"].isin(cosine_scores.keys())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ClLiBEVrrHGC",
      "metadata": {
        "id": "ClLiBEVrrHGC",
        "outputId": "e6aafeaa-0c47-492b-bf87-31f9de67afe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-52c7c97f84fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mword2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_20_bm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_20_custom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_20_cosine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-52c7c97f84fa>\u001b[0m in \u001b[0;36mword2vec\u001b[0;34m(tweets)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Word2VecKeyedVectors' object has no attribute 'key_to_index'"
          ]
        }
      ],
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def word2vec(tweets):\n",
        "    clean_tweets = []\n",
        "    for tweet in tweets.itertuples(index=True): \n",
        "            clean_tweets.append(str(tweet.full_text))\n",
        "    model = Word2Vec(clean_tweets, workers=4, min_count=50, window=10, sample=1e-3)\n",
        "\n",
        "    X = model.wv[model.wv.key_to_index]\n",
        "\n",
        "    tsne = TSNE(n_components=2, perplexity=1)\n",
        "    X_tsne = tsne.fit_transform(X)\n",
        "\n",
        "    plt.scatter(X_tsne[:, 0], X_tsne[:, 1])\n",
        "\n",
        "    plt.show()\n",
        "word2vec(top_20_bm)\n",
        "word2vec(top_20_custom)\n",
        "word2vec(top_20_cosine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08789fd-4a1e-4cb0-86cd-a88e965b4b2d",
      "metadata": {
        "id": "b08789fd-4a1e-4cb0-86cd-a88e965b4b2d"
      },
      "outputs": [],
      "source": [
        "top_docs_per_query = {query: cosine_score(query, k=20) for query in queries}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd6a456-8f54-45bc-b761-3cf013a0dc32",
      "metadata": {
        "id": "1dd6a456-8f54-45bc-b761-3cf013a0dc32"
      },
      "outputs": [],
      "source": [
        "top_docs_per_query"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}